{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Gastebois Jacques - Ei2i / Polytech\n",
                "## Benchmarking : Validation de la Distillation sur Nouvelles Architectures\n",
                "\n",
                "Comme jâ€™ai pu le constater lors de mes missions chez Funky Junk, la polyvalence est la cle de la reussite technique. Ce notebook a pour but de valider que nos images distilles ne sont pas \"sur-apprises\" pour un seul modele, mais qu'elles peuvent servir de base d'entrainement pour n'importe quel reseau.\n",
                "\n",
                "C'est l'essence meme de mon ambition : **DEVENIR INGENIEUR POUR LES INGENIEURS**. Fournir des outils robustes et verifies.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. chargement des outils d'evaluation\n",
                "\n",
                "on reprend les utilitaires du papier original pour etre sur de pas dire de betises sur les chiffres. j'ai un peu fait le menage dans les imports mais ca reste un peu le bazar. :)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as  nn\n",
                "import numpy as  np\n",
                "import os \n",
                "from utils import get_dataset, get_network, evaluate_synset\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    dev = 'cuda'\n",
                "elif torch.backends.mps.is_available():\n",
                "\tdev =  'mps' # pour mon m2 fetiche\n",
                "else:\n",
                "    dev = 'cpu'\n",
                "    \n",
                "print(f\"on evalue sur {dev} !!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. recuperation des images et du modele\n",
                "\n",
                "on va charger les images qu'on a sauvees dans le notebook 1. \n",
                "faut faire gaffe a bien donner le bon chemin. j'ai tendance a me perdre dans mes dossiers a force de faire de l'electronique et de l'info en meme temps. :p"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class eval_args:\n",
                "    dataset = 'CIFAR10'\n",
                "    model = 'ConvNet' # on peut changer pour ResNet18 si on veut rigoler\n",
                "    epoch_eval_train = 1000 # temps d'entrainement sur le synset\n",
                "    lr_net = 0.01\n",
                "    batch_train = 256\n",
                "    device = dev\n",
                "    pca = False \n",
                "    zca = True # important si on l'a mis a la distillation !!!\n",
                "    \n",
                "config = eval_args()\n",
                "\n",
                "# chemin vers les resultats du notebook 1\n",
                "data_path = './logged_files/CIFAR10/ton_run_ici'\n",
                "img_syn = torch.load(os.path.join(data_path, 'images_best.pt'), map_location=dev)\n",
                "lab_syn = torch.load(os.path.join(data_path, 'labels_best.pt'), map_location=dev)\n",
                "\n",
                "print(\"donnees chargees pour le benchmark :)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. entrainement et mesure de l'accuracy\n",
                "\n",
                "on lance l'entrainement d'un nouveau modele a partir de zero, mais seulement sur nos 10 images (pour ipc=1). \n",
                "ensuite on le teste sur les vraies donnees de cifar10 qu'il n'a jamais vues. c'est le moment de verite. :o"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"chargement du vrai set de test pour la validation...\")\n",
                "_, _, _, _, _, _, _, _, test_loader, _, _, _ = get_dataset(config.dataset, './data', 256, '', args=config)\n",
                "\n",
                "def run_benchmark(model_name):\n",
                "    print(f\"\\\\nevaluation sur {model_name} en cours...\")\n",
                "    \n",
                "    # on cree le reseau tout neuf\n",
                "    net = get_network(model_name, 3, 10, (32,32)).to(dev)\n",
                "    \n",
                "    # on utilise la fonction evaluate du repo pour pas se planter dans les calculs\n",
                "    # c'est pascal antonini qui m'a appris l'importance de la precision dans les mesures :)\n",
                "    _, acc_train, acc_test = evaluate_synset(0, net, img_syn, lab_syn, test_loader, config)\n",
                "    \n",
                "    print(f\"resultat final pour {model_name} :\") \n",
                "\tprint( f\"   accuracy train (sur le synset) : {acc_train:.2%}\")\n",
                "    print(f\"   accuracy test (sur cifar10)  : {acc_test:.2%}\")\n",
                "    \n",
                "    return acc_test\n",
                "\n",
                "# on teste sur le modele de base\n",
                "run_benchmark('ConvNet')\n",
                "\n",
                "# si t'as le temps essaye avec ca\n",
                "# run_benchmark('AlexNet') # c'est un peu plus lourd mais ca se fait :p"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. conclusion du benchmark\n",
                "\n",
                "si on depasse les 40%, on est dans les clous du papier original. mon record est a 46.3%.\n",
                "ca montre bien que meme avec tres peu de moyens (comme au debut de Funky Junk dans l'entrepot d'Ansiere), on peut faire du travail de qualite pro. \n",
                "\n",
                "merci a thibault hilaire pour ses conseils sur la partie systeme et a mme malonga pour l'aide sur la redaction du rapport. :)\n",
                "\n",
                "Jacques Gastebois - 2026"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}