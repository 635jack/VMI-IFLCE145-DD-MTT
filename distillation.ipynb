{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Gastebois Jacques\n",
                "## Projet MTT : Distillation de Dataset par Correspondance de Trajectoires\n",
                "\n",
                "Ce notebook constitue la partie principale de mon travail sur la reproduction du papier MTT. \n",
                "L'objectif est de condenser un dataset en un petit nombre d'images synthetiques tout en conservant une bonne performance de test.\n",
                "\n",
                "**Note :** Ce notebook est une version epuree prevue pour tourner avec les buffers experts deja generes. \n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. initialisation et imports de base\n",
                "\n",
                "on commence par charger tout le bousin necessaire. j'ai garde kornia pour les augmentations parce que c'est ce qui marche le mieux pour le mps sur mon m2. (enfin j'espere :))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as  np\n",
                "from tqdm import tqdm\n",
                "import copy\n",
                "import  random\n",
                "\n",
                "# imports du projet original\n",
                "from utils import get_dataset, get_network, get_eval_pool, evaluate_synset, get_time, DiffAugment, ParamDiffAug\n",
                "from reparam_module import  ReparamModule\n",
                "\n",
                "def setup_device():\n",
                "    # petite verif pour savoir ou on en est\n",
                "    if torch.cuda.is_available():\n",
                "        dev = 'cuda'\n",
                "    elif   torch.backends.mps.is_available():\n",
                "        dev = 'mps'\n",
                "    else :\n",
                "        dev = 'cpu'\n",
                "    print(f\"on tourne sur {dev} :)\")\n",
                "    return  dev\n",
                "    \n",
                "DEVICE = setup_device()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. reglages et hyper-parametres\n",
                "\n",
                "j'ai mis les reglages du papier par defaut mais pour les tests j'ai tendance a baisser le nombre d'iterations. les noms des variables sont pas forcement tres rigides mais on s'y retrouve. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class config:\n",
                "    dataset = 'CIFAR10' \n",
                "    model =   'ConvNet'\n",
                "    ipc = 1 # une image par classe c'est deja pas mal\n",
                "    iter = 5000\n",
                "    \n",
                "    # reglages de l'optimiseur\n",
                "    lr_img = 1000.0\n",
                "    lr_net_param =  1e-05\n",
                "    initial_lr = 0.01\n",
                "    \n",
                "    # chemins pour les donnees\n",
                "    path_data = './data'\n",
                "    # c'est ici qu'on met les buffers herberges sur hf\n",
                "    path_buffer =  './buffers_c10_full'\n",
                "    \n",
                "    # parametres mtt\n",
                "    expert_epochs = 3 \n",
                "    syn_steps = 20\n",
                "    max_start = 20\n",
                "    \n",
                "    zca = True # important pour cifar10 sinon ca converge pas top\n",
                "\n",
                "args = config()\n",
                "args.device = DEVICE\n",
                "args.batch_real = 256\n",
                "args.dsa_param = ParamDiffAug() # pour les augmentations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. preparation des donnees\n",
                "\n",
                "c'est la partie un peu penible ou on charge tout en memoire. faut etre patient :)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"chargement du dataset en cours...\")\n",
                "\n",
                "chan, size, classes, names, m, s, train_set, test_set, t_loader, loader_dict, c_map, c_map_inv = get_dataset(args.dataset, args.path_data, args.batch_real, '',  args=args)\n",
                "\n",
                "# initialisation des images synthetiques\n",
                "labels_syn = torch.tensor([np.ones(args.ipc,dtype=np.int_)*i for i in range(classes)], dtype=torch.long, requires_grad=False, device=DEVICE).view(-1)\n",
                "\n",
                "# on part de quelque chose de realiste si possible\n",
                "images_syn = torch.randn(size=(classes * args.ipc, chan, size[0],  size[1]), dtype=torch.float, device=DEVICE, requires_grad=True)\n",
                "\n",
                "print(f\"pret pour {classes} classes avec {args.ipc} images chaque\")\n",
                "\n",
                "# reglages des optimiseurs pour les images et le lr\n",
                "opt_img = torch.optim.SGD([images_syn], lr=args.lr_img,  momentum=0.5)\n",
                "lr_syn = torch.tensor(args.initial_lr).to(DEVICE).requires_grad_(True)\n",
                "opt_lr = torch.optim.SGD([lr_syn], lr=args.lr_net_param, momentum=0.5)\n",
                "\n",
                "print(\"optimiseurs ok :)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. boucle de distillation (mtt)\n",
                "\n",
                "le gros du morceau. on essaye de copier ce que l'expert a fait pendant son entrainement.\n",
                "si ca deconne au milieu c'est surement les buffers qui sont pas au bon endroit. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# chargement des trajectoires expertes\n",
                "buffer_dir = os.path.join(args.path_buffer, args.dataset, \"ConvNet\")\n",
                "print(f\"recherche des experts dans {buffer_dir}\")\n",
                "\n",
                "# on charge le premier fichier pour voir\n",
                "try:\n",
                "    experts = torch.load(os.path.join(buffer_dir, \"replay_buffer_0.pt\"))\n",
                "    print(f\"on a {len(experts)} trajectoires chargees :)\")\n",
                "except:\n",
                "    print(\"oups pas pu charger les buffers. verifie le chemin ou si t'as bien telecharge depuis hf\")\n",
                "    experts = [] \n",
                "\n",
                "def distillation_loop( iters):\n",
                "    for it in  range(iters+1):\n",
                "        \n",
                "        # 1. on pioche un expert au pif\n",
                "        trajectoire = random.choice(experts)\n",
                "        \n",
                "        # 2. on choisit un moment de sa vie (epoch)\n",
                "        start_e = np.random.randint(0,  args.max_start)\n",
                "        starting_params = trajectoire[start_e]\n",
                "        target_params   = trajectoire[start_e + args.expert_epochs]\n",
                "        \n",
                "        # on met ca sous forme de vecteur plat\n",
                "        target_p = torch.cat([p.data.to(DEVICE).reshape(-1) for p in target_params], 0)\n",
                "        \n",
                "        # 3. on cree notre eleve (student)\n",
                "        eleve = get_network(args.model, chan, classes, size).to(DEVICE)\n",
                "        eleve = ReparamModule(eleve)\n",
                "        eleve.train()\n",
                "\n",
                "        # on lui donne les parametres de depart de l'expert\n",
                "        p_eleve = [torch.cat([p.data.to(DEVICE).reshape(-1) for p in starting_params], 0).requires_grad_(True)]\n",
                "        \n",
                "        # 4. on fait faire des pas a l'eleve sur nos images bidon\n",
                "        for  step in range(args.syn_steps):\n",
                "             # petites augmentations au passage\n",
                "             x = DiffAugment(images_syn, 'color_crop_cutout_flip_scale_rotate', param=args.dsa_param)\n",
                "             \n",
                "             out = eleve(x, flat_param=p_eleve[-1])\n",
                "             loss = nn.CrossEntropyLoss()(out, labels_syn)\n",
                "             \n",
                "             # calcul du gradient pour le student\n",
                "             grad = torch.autograd.grad(loss, p_eleve[-1], create_graph=True)[0]\n",
                "             p_eleve.append(p_eleve[-1] -  lr_syn * grad)\n",
                "             \n",
                "        # 5. on regarde si on est loin de l'expert\n",
                "        perte_mtt = nn.functional.mse_loss(p_eleve[-1], target_p, reduction=\"sum\")\n",
                "        \n",
                "        # mise a jour de nos images synthetiques\n",
                "        opt_img.zero_grad()\n",
                "        opt_lr.zero_grad()\n",
                "        \n",
                "        perte_mtt.backward()\n",
                "        \n",
                "        opt_img.step()\n",
                "        opt_lr.step()\n",
                "        \n",
                "        if  it % 10 == 0:\n",
                "            print(f\"iteration {it} - perte : {perte_mtt.item():.4f} :)\")\n",
                "\n",
                "# a lancer quand t'es pret\n",
                "# distillation_loop(args.iter)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}